import streamlit as st
import cv2
import numpy as np
import os
from pathlib import Path
import face_recognition

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑ –ª–∏—Ü –≤ –≤–∏–¥–µ–æ",
    page_icon="üé•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
def create_directories():
    try:
        Path("storage/videos").mkdir(parents=True, exist_ok=True)
        Path("storage/results").mkdir(parents=True, exist_ok=True)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {str(e)}")
        raise

# –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü
def analyze_video(video_path):
    try:
        cap = cv2.VideoCapture(video_path)
        frame_count = 0
        detected_faces = []

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1
            if frame_count % 10 != 0:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π 10-–π –∫–∞–¥—Ä
                continue

            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            face_locations = face_recognition.face_locations(rgb_frame)

            for face_location in face_locations:
                top, right, bottom, left = face_location
                detected_faces.append((frame_count, top, right, bottom, left))

        cap.release()
        return detected_faces
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤–∏–¥–µ–æ: {str(e)}"

# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
st.header("üé• –ê–Ω–∞–ª–∏–∑ –ª–∏—Ü –≤ –≤–∏–¥–µ–æ")

uploaded_file = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª (MP4)",
    type=["mp4"],
    help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ MP4"
)

if uploaded_file is not None:
    create_directories()
    video_path = f"storage/videos/{uploaded_file.name}"
    
    with open(video_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.success("–í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!")
    
    if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –ª–∏—Ü"):
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ..."):
            results = analyze_video(video_path)
            
            if isinstance(results, str):
                st.error(results)
            else:
                st.success(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(results)} –ª–∏—Ü –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –∫–∞–¥—Ä–∞—Ö –≤–∏–¥–µ–æ.")
                st.write(results)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                results_path = f"storage/results/{uploaded_file.name}_faces.txt"
                with open(results_path, "w") as f:
                    for entry in results:
                        f.write(f"Frame: {entry[0]}, Top: {entry[1]}, Right: {entry[2]}, Bottom: {entry[3]}, Left: {entry[4]}\n")
                
                with open(results_path, "r") as f:
                    st.download_button(
                        label="üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
                        data=f.read(),
                        file_name=f"{uploaded_file.name}_faces.txt",
                        mime="text/plain"
                    )

# –ù–∏–∂–Ω–∏–π –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        ¬© 2024 –ê–Ω–∞–ª–∏–∑ –ª–∏—Ü –≤ –≤–∏–¥–µ–æ | –í–µ—Ä—Å–∏—è 1.0
    </div>
    """,
    unsafe_allow_html=True 
)
